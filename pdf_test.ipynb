{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (0.0.136)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (1.10.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.2)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: openai in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (0.27.4)\n",
      "Requirement already satisfied: tqdm in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from PyPDF2) (4.5.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m518.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.3\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Using cached regex-2023.3.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlp-lab/anaconda3/envs/open_ai/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.3.23 tiktoken-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.zshrc\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./Atomic_Habits.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN\tIMPRINT\tOF\t\n",
      "P\n",
      "ENGUIN\t\n",
      "R\n",
      "AND\n",
      "OM\t\n",
      "H\n",
      "OUSE\t\n",
      "LLC\n",
      "375\n"
     ]
    }
   ],
   "source": [
    "raw_text = ''\n",
    "for i, page in enumerate(pages):\n",
    "    text = page.page_content\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "print(raw_text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator= \"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    )\n",
    "\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving\tthe\tBritish\tteam\tfive\tTour\tde\tFrance\tvictories\tin\tsix\tyears.\n",
      "During\tthe\tten-year\tspan\tfrom\t2007\tto\t2017,\tBritish\tcyclists\twon\n",
      "178\tworld\tchampionships\tand\tsixty-six\tOlympic\tor\tParalympic\tgold\n",
      "medals\tand\tcaptured\tfive\tTour\tde\tFrance\tvictories\tin\twhat\tis\twidely\n",
      "regarded\tas\tthe\tmost\tsuccessful\trun\tin\tcycling\thistory.\n",
      "*\n",
      "How\tdoes\tthis\thappen?\tHow\tdoes\ta\tteam\tof\tpreviously\tordinary\n",
      "athletes\ttransform\tinto\tworld\tchampions\twith\ttiny\tchanges\tthat,\tat\n"
     ]
    }
   ],
   "source": [
    "print(texts[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "docsearch = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x7f5970420910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The fundamentals of human behavior according to this book are the Four Laws of Behavior Change: situation to situation, moment to moment, second to second. These laws explain how to create good habits and break bad ones.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the fundaments according to this book\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='describes\\tthe\\tbest\\tway\\tI\\tknow—an\\tapproach\\tthat\\twill\\tbe\\teffective\\nregardless\\tof\\twhere\\tyou\\tstart\\tor\\twhat\\tyou’re\\ttrying\\tto\\tchange.\\tThe\\nstrategies\\tI\\tcover\\twill\\tbe\\trelevant\\tto\\tanyone\\tlooking\\tfor\\ta\\tstep-by-step\\nsystem\\tfor\\timprovement,\\twhether\\tyour\\tgoals\\tcenter\\ton\\thealth,\\tmoney,\\nproductivity,\\trelationships,\\tor\\tall\\tof\\tthe\\tabove.\\tAs\\tlong\\tas\\thuman\\nbehavior\\tis\\tinvolved,\\tthis\\tbook\\twill\\tbe\\tyour\\tguide.THE\\n\\t\\nFUNDAMENTALS\\nWhy\\tTiny\\tChanges\\tMake\\ta\\tBig\\t\\nDifferenceT\\n1\\nThe\\tSurprising\\tPower\\tof\\tAtomic\\tHabits\\nHE\\tFATE', metadata={}),\n",
       " Document(page_content='applications\\tof\\tthe\\tFour\\tLaws\\tof\\tBehavior\\tChange—will\\toffer\\ta\\tnew\\nway\\tto\\tthink\\tabout\\tyour\\thabits.\\nHuman\\tbehavior\\tis\\talways\\tchanging:\\tsituation\\tto\\tsituation,\\tmoment\\nto\\tmoment,\\tsecond\\tto\\tsecond.\\tBut\\tthis\\tbook\\tis\\tabout\\twhat\\t\\ndoesn’t\\nchange.\\tIt’s\\tabout\\tthe\\tfundamentals\\tof\\thuman\\tbehavior.\\tThe\\tlasting\\nprinciples\\tyou\\tcan\\trely\\ton\\tyear\\tafter\\tyear.\\tThe\\tideas\\tyou\\tcan\\tbuild\\ta\\nbusiness\\taround,\\tbuild\\ta\\tfamily\\taround,\\tbuild\\ta\\tlife\\taround.\\nThere\\tis\\tno\\tone\\tright\\tway\\tto\\tcreate\\tbetter\\thabits,\\tbut\\tthis\\tbook', metadata={}),\n",
       " Document(page_content='put\\ttogether\\ta\\tbrief\\tguide\\ton\\thow\\tto\\tapply\\tthese\\tideas\\tspecifically\\tto\\nparenting.\\nYou\\tcan\\tdownload\\tthis\\tchapter\\tat:\\t\\natomichabits.com/\\nparentingI\\nAcknowledgments\\nHAVE\\tRELIED\\tHEAVILY\\t\\non\\tothers\\tduring\\tthe\\tcreation\\tof\\tthis\\tbook.\\tBefore\\nanyone\\telse,\\tI\\tmust\\tthank\\tmy\\twife,\\tKristy,\\twho\\thas\\tbeen\\nindispensable\\tthroughout\\tthis\\tprocess.\\tShe\\thas\\tplayed\\tevery\\trole\\ta\\nperson\\tcan\\tplay\\tin\\tthe\\twriting\\tof\\ta\\tbook:\\tspouse,\\tfriend,\\tfan,\\tcritic,\\neditor,\\tresearcher,\\ttherapist.\\tIt\\tis\\tno\\texaggeration\\tto\\tsay\\tthis\\tbook', metadata={}),\n",
       " Document(page_content='and\\tbreaking\\tbad\\tones\\tis\\tto\\tunderstand\\tthese\\tfundamental\\tlaws\\tand\\nhow\\tto\\talter\\tthem\\tto\\tyour\\tspecifications.\\tEvery\\tgoal\\tis\\tdoomed\\tto\\tfail\\tif\\nit\\tgoes\\tagainst\\tthe\\tgrain\\tof\\thuman\\tnature.\\nYour\\thabits\\tare\\tshaped\\tby\\tthe\\tsystems\\tin\\tyour\\tlife.\\tIn\\tthe\\tchapters\\nthat\\tfollow,\\twe\\twill\\tdiscuss\\tthese\\tlaws\\tone\\tby\\tone\\tand\\tshow\\thow\\tyou\\ncan\\tuse\\tthem\\tto\\tcreate\\ta\\tsystem\\tin\\twhich\\tgood\\thabits\\temerge\\tnaturally\\nand\\tbad\\thabits\\twither\\taway.\\nChapter\\tSummary\\nA\\thabit\\tis\\ta\\tbehavior\\tthat\\thas\\tbeen\\trepeated\\tenough\\ttimes\\tto', metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'describes\\tthe\\tbest\\tway\\tI\\tknow—an\\tapproach\\tthat\\twill\\tbe\\teffective\\nregardless\\tof\\twhere\\tyou\\tstart\\tor\\twhat\\tyou’re\\ttrying\\tto\\tchange.\\tThe\\nstrategies\\tI\\tcover\\twill\\tbe\\trelevant\\tto\\tanyone\\tlooking\\tfor\\ta\\tstep-by-step\\nsystem\\tfor\\timprovement,\\twhether\\tyour\\tgoals\\tcenter\\ton\\thealth,\\tmoney,\\nproductivity,\\trelationships,\\tor\\tall\\tof\\tthe\\tabove.\\tAs\\tlong\\tas\\thuman\\nbehavior\\tis\\tinvolved,\\tthis\\tbook\\twill\\tbe\\tyour\\tguide.THE\\n\\t\\nFUNDAMENTALS\\nWhy\\tTiny\\tChanges\\tMake\\ta\\tBig\\t\\nDifferenceT\\n1\\nThe\\tSurprising\\tPower\\tof\\tAtomic\\tHabits\\nHE\\tFATE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    docs = docsearch.similarity_search(name)\n",
    "    return chain.run(input_documents=docs, question=name)\n",
    "\n",
    "\n",
    "myServer = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "myServer.launch(server_name=\"0.0.0.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
